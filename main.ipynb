{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import cv2\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def load_images_from_folder(folder):\r\n",
    "    images = []\r\n",
    "    for filename in os.listdir(folder):\r\n",
    "        img_path = os.path.join(folder, filename)\r\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\r\n",
    "        if img is not None:\r\n",
    "            images.append(img)\r\n",
    "    return images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "infected_folder = 'Infected'\r\n",
    "infected_images = load_images_from_folder(infected_folder)\r\n",
    "n_infected_folder = 'Not_Infected'\r\n",
    "n_intected_images = load_images_from_folder(n_infected_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "itr = round(501*0.7)\r\n",
    "ival = round(550*0.1)\r\n",
    "ite = round(501*0.2)\r\n",
    "\r\n",
    "ntr = round(550*0.7)\r\n",
    "nval = round(550*0.1)\r\n",
    "nte = round(550*0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "covid_dir = 'Covid_CT'\r\n",
    "os.mkdir(covid_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# train, val, test folder\r\n",
    "train_dir = './Covid_CT/train'\r\n",
    "val_dir = './Covid_CT/val'\r\n",
    "test_dir = './Covid_CT/test'\r\n",
    "\r\n",
    "os.mkdir(train_dir)\r\n",
    "os.mkdir(val_dir)\r\n",
    "os.mkdir(test_dir)\r\n",
    "\r\n",
    "# infected folder\r\n",
    "in_train = './Covid_CT/train/infected'\r\n",
    "in_val = './Covid_CT/val/infected'\r\n",
    "in_test = './Covid_CT/test/infected'\r\n",
    "\r\n",
    "os.mkdir(in_train)\r\n",
    "os.mkdir(in_val)\r\n",
    "os.mkdir(in_test)\r\n",
    "\r\n",
    "#not infected folder\r\n",
    "not_in_train = './Covid_CT/train/Not_infected'\r\n",
    "not_in_val = './Covid_CT/val/Not_infected'\r\n",
    "not_in_test = './Covid_CT/test/Not_infected'\r\n",
    "\r\n",
    "os.mkdir(not_in_train)\r\n",
    "os.mkdir(not_in_val)\r\n",
    "os.mkdir(not_in_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def infected_images_to_folder(infected_images, train_dir, val_dir, test_dir):\r\n",
    "    for i in range(len(infected_images)):\r\n",
    "        img_name = \"{}.jpg\".format(i)\r\n",
    "        if i in range(0, itr+1):\r\n",
    "            cv2.imwrite(os.path.join(train_dir, img_name), infected_images[i])\r\n",
    "        elif i in range(itr+1, itr+ival+1):\r\n",
    "            cv2.imwrite(os.path.join(val_dir, img_name), infected_images[i])\r\n",
    "        else:\r\n",
    "            cv2.imwrite(os.path.join(test_dir, img_name), infected_images[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def not_infected_images_to_folder(n_intected_images, train_dir, val_dir, test_dir):\r\n",
    "    for i in range(len(n_intected_images)):\r\n",
    "        img_name = \"{}.jpg\".format(i)\r\n",
    "        if i in range(0, ntr+1):\r\n",
    "            cv2.imwrite(os.path.join(train_dir, img_name), n_intected_images[i])\r\n",
    "        elif i in range(ntr+1, ntr+nval+1):\r\n",
    "            cv2.imwrite(os.path.join(val_dir, img_name), n_intected_images[i])\r\n",
    "        else:\r\n",
    "            cv2.imwrite(os.path.join(test_dir, img_name), n_intected_images[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "infected_images_to_folder(infected_images, './Covid_CT/train/infected', './Covid_CT/val/infected', './Covid_CT/test/infected')\r\n",
    "not_infected_images_to_folder(n_intected_images, './Covid_CT/train/Not_infected', './Covid_CT/val/Not_infected', './Covid_CT/test/Not_infected')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "IMAGE_ROWS = 256\r\n",
    "IMAGE_COLS = 256\r\n",
    "BATCH_SIZE = 30\r\n",
    "IMAGE_SHAPE = (IMAGE_ROWS, IMAGE_COLS, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras import models\r\n",
    "\r\n",
    "model = models.Sequential()\r\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=IMAGE_SHAPE))\r\n",
    "model.add(layers.MaxPooling2D((2,2)))\r\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\r\n",
    "model.add(layers.MaxPooling2D((2,2)))\r\n",
    "model.add(layers.Flatten())\r\n",
    "model.add(layers.Dropout(0.5))\r\n",
    "model.add(layers.Dense(128, activation='relu'))\r\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
    "model.summary()\r\n",
    "\r\n",
    "from tensorflow.keras import optimizers\r\n",
    "\r\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\r\n",
    "              loss='binary_crossentropy',\r\n",
    "              metrics=['acc'])\r\n",
    "\r\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n",
    "vali_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "    train_dir,\r\n",
    "    target_size = (150, 150),\r\n",
    "    batch_size = 30,\r\n",
    "    class_mode = 'binary',\r\n",
    "    color_mode='grayscale'\r\n",
    ")\r\n",
    "\r\n",
    "validation_generator = vali_datagen.flow_from_directory(\r\n",
    "    val_dir,\r\n",
    "    target_size = (150, 150),\r\n",
    "    batch_size = 30,\r\n",
    "    class_mode = 'binary',\r\n",
    "    color_mode='grayscale'\r\n",
    ")\r\n",
    "\r\n",
    "test_generator = test_datagen.flow_from_directory(\r\n",
    "    test_dir,\r\n",
    "    target_size = (150, 150),\r\n",
    "    batch_size = 30,\r\n",
    "    class_mode = 'binary',\r\n",
    "    color_mode='grayscale'\r\n",
    ")\r\n",
    "\r\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=15, epochs=10, validation_data = validation_generator, validation_steps = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
    "    rescale = 1./255,\r\n",
    "    rotation_range = 40,\r\n",
    "    width_shift_range = 0.2,\r\n",
    "    height_shift_range = 0.2,\r\n",
    "    shear_range = 0.2,\r\n",
    "    zoom_range=0.2,\r\n",
    "    horizontal_flip = True,\r\n",
    "    fill_mode = 'nearest'\r\n",
    ")\r\n",
    "\r\n",
    "vali_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "    train_dir,\r\n",
    "    target_size = (150, 150),\r\n",
    "    batch_size = 30,\r\n",
    "    class_mode = 'binary',\r\n",
    "    color_mode='grayscale'\r\n",
    ")\r\n",
    "\r\n",
    "validation_generator = vali_datagen.flow_from_directory(\r\n",
    "    val_dir,\r\n",
    "    target_size = (150, 150),\r\n",
    "    batch_size = 30,\r\n",
    "    class_mode = 'binary',\r\n",
    "    color_mode='grayscale'\r\n",
    ")\r\n",
    "\r\n",
    "test_generator = test_datagen.flow_from_directory(\r\n",
    "    test_dir,\r\n",
    "    target_size = (150, 150),\r\n",
    "    batch_size = 30,\r\n",
    "    class_mode = 'binary',\r\n",
    "    color_mode='grayscale'\r\n",
    ")\r\n",
    "\r\n",
    "# 2. Dropout 추가 및 Dense Node를 줄인다. & 4. 이미지 픽셀을 더 작게 150*150으로 축소한다.\r\n",
    "IMAGE_ROWS = 150\r\n",
    "IMAGE_COLS = 150\r\n",
    "BATCH_SIZE = 30\r\n",
    "IMAGE_SHAPE = (IMAGE_ROWS,IMAGE_COLS,1)\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras import models\r\n",
    "\r\n",
    "model2 = models.Sequential()\r\n",
    "model2.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=IMAGE_SHAPE))\r\n",
    "model2.add(layers.MaxPooling2D((2,2)))\r\n",
    "model2.add(layers.Dropout(0.5))\r\n",
    "model2.add(layers.Conv2D(64, (3,3), activation='relu'))\r\n",
    "model2.add(layers.MaxPooling2D((2,2)))\r\n",
    "model2.add(layers.Flatten())\r\n",
    "model2.add(layers.Dropout(0.5))\r\n",
    "model2.add(layers.Dense(64, activation='relu'))\r\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\r\n",
    "\r\n",
    "model2.summary()\r\n",
    "\r\n",
    "from tensorflow.keras import optimizers\r\n",
    "\r\n",
    "model2.compile(optimizer=optimizers.Adam(learning_rate=1e-4), # 'rmsprop',\r\n",
    "               loss='binary_crossentropy',\r\n",
    "               metrics=['acc'])\r\n",
    "\r\n",
    "history2 = model2.fit_generator(train_generator, steps_per_epoch=15, epochs=10, validation_data = validation_generator, validation_steps = 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 738 images belonging to 2 classes.\n",
      "Found 110 images belonging to 2 classes.\n",
      "Found 203 images belonging to 2 classes.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 148, 148, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                5308480   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,327,361\n",
      "Trainable params: 5,327,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 0.6967 - acc: 0.5111 - val_loss: 0.7580 - val_acc: 0.4667\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 6s 393ms/step - loss: 0.6563 - acc: 0.5378 - val_loss: 0.7381 - val_acc: 0.1333\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 6s 390ms/step - loss: 0.6484 - acc: 0.5733 - val_loss: 0.7411 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 0.6068 - acc: 0.6324 - val_loss: 0.7047 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 6s 392ms/step - loss: 0.6100 - acc: 0.6484 - val_loss: 0.7479 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 5s 353ms/step - loss: 0.6373 - acc: 0.6142 - val_loss: 0.7095 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 5s 365ms/step - loss: 0.6005 - acc: 0.6467 - val_loss: 0.7184 - val_acc: 0.2667\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 6s 428ms/step - loss: 0.5580 - acc: 0.6895 - val_loss: 0.7481 - val_acc: 0.2667\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 0.5809 - acc: 0.6507 - val_loss: 0.6905 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 6s 428ms/step - loss: 0.5664 - acc: 0.6598 - val_loss: 0.6514 - val_acc: 0.5333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "b69a98d3df882577ba469635c4ab08c5ae67eaedfd3a57f311f98966a6edb2d0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}